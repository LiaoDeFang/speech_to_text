import os
import json
import sys
import math
import subprocess

# å˜—è©¦å°å…¥ OpenAIï¼Œå¦‚æœå¤±æ•—å‰‡çµ¦å‡ºæ¸…æ™°çš„éŒ¯èª¤ä¿¡æ¯
try:
    from openai import AzureOpenAI
except ImportError as e:
    print("âŒ OpenAI åº«å°å…¥å¤±æ•—ï¼")
    print("è«‹é‹è¡Œ: pip install --upgrade openai")
    sys.exit(1)

# --- Configuration ---
API_KEY = os.environ.get('AZURE_API_KEY', "5xF9YpUcEKxYt6IhIBywab0gAuQEMoJhtpASxkVuSPSQjSFGcgMmJQQJ99BEACHYHv6XJ3w3AAAAACOGYygR")
AZURE_ENDPOINT = os.environ.get('AZURE_ENDPOINT', "https://silve-magk0is1-eastus2.cognitiveservices.azure.com/")
WHISPER_MODEL = "my-gemini-recorder"
GPT_MODEL = "my-gemini-finetuner"
WHISPER_API_VERSION = "2024-06-01"
GPT_API_VERSION = "2024-12-01-preview"

def test_openai_version():
    """æ¸¬è©¦ OpenAI åº«ç‰ˆæœ¬"""
    try:
        import openai
        print(f"âœ… OpenAI ç‰ˆæœ¬: {openai.__version__}")
        
        # æ¸¬è©¦ AzureOpenAI åˆå§‹åŒ–
        client = AzureOpenAI(
            api_key="test",
            api_version="2024-06-01",
            azure_endpoint="https://test.openai.azure.com/"
        )
        print("âœ… AzureOpenAI å®¢æˆ¶ç«¯åˆå§‹åŒ–æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âŒ OpenAI åº«æ¸¬è©¦å¤±æ•—: {e}")
        return False

def get_file_size_mb(file_path):
    """ç²å–æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰"""
    return os.path.getsize(file_path) / (1024 * 1024)

def split_audio_with_ffmpeg(file_path, max_size_mb=20):
    """ä½¿ç”¨ ffmpeg åˆ†å‰²éŸ³é »æ–‡ä»¶ï¼ˆå¦‚æœå¯ç”¨ï¼‰"""
    file_size_mb = get_file_size_mb(file_path)
    
    if file_size_mb <= max_size_mb:
        print(f"æ–‡ä»¶å¤§å° {file_size_mb:.2f}MBï¼Œç„¡éœ€åˆ†å‰²")
        return [file_path]
    
    print(f"æ–‡ä»¶å¤ªå¤§ ({file_size_mb:.2f}MB)ï¼Œå˜—è©¦åˆ†å‰²...")
    
    try:
        # æª¢æŸ¥æ˜¯å¦æœ‰ ffmpeg
        subprocess.run(['ffmpeg', '-version'], capture_output=True, check=True)
        print("âœ… æ‰¾åˆ° ffmpegï¼Œé–‹å§‹åˆ†å‰²")
        
        # ç²å–éŸ³é »æ™‚é•·
        result = subprocess.run([
            'ffprobe', '-v', 'quiet', '-show_entries', 
            'format=duration', '-of', 'csv=p=0', file_path
        ], capture_output=True, text=True, check=True)
        
        duration = float(result.stdout.strip())
        num_chunks = math.ceil(file_size_mb / max_size_mb)
        chunk_duration = duration / num_chunks
        
        chunks = []
        temp_dir = "temp_audio_chunks"
        if not os.path.exists(temp_dir):
            os.makedirs(temp_dir)
        
        for i in range(num_chunks):
            start_time = i * chunk_duration
            chunk_path = os.path.join(temp_dir, f"chunk_{i+1}.mp3")
            
            subprocess.run([
                'ffmpeg', '-i', file_path, '-ss', str(start_time),
                '-t', str(chunk_duration), '-c', 'copy', chunk_path, '-y'
            ], capture_output=True, check=True)
            
            chunks.append(chunk_path)
            print(f"  - å‰µå»ºåˆ†æ®µ {i+1}/{num_chunks}")
        
        return chunks
        
    except (subprocess.CalledProcessError, FileNotFoundError):
        print("âŒ ffmpeg ä¸å¯ç”¨ï¼Œç„¡æ³•åˆ†å‰²å¤§æ–‡ä»¶")
        return [file_path]  # è¿”å›åŸæ–‡ä»¶ï¼Œè®“ API è™•ç†

def transcribe_chunk(client, chunk_path):
    """è½‰éŒ„éŸ³é »åˆ†æ®µ"""
    try:
        with open(chunk_path, 'rb') as audio_file:
            transcript = client.audio.transcriptions.create(
                model=WHISPER_MODEL,
                file=audio_file
            )
        return transcript.text
    except Exception as e:
        return f"[è½‰éŒ„éŒ¯èª¤: {e}]"

def fine_tune_transcript(client, raw_transcript, filename):
    """ä½¿ç”¨ GPT-4.1 æ”¹å–„è½‰éŒ„"""
    prompt = f"""è«‹æ”¹å–„æ­¤éŸ³é »è½‰éŒ„ï¼Œé‡é»åŒ…æ‹¬ï¼š

1. **Grammar and Punctuation**: Fix grammar errors, add proper punctuation, and correct sentence structure
2. **Formatting**: Organize into clear paragraphs and proper markdown format
3. **Speaker Identification**: If multiple speakers are detected, separate them clearly
4. **Filler Words**: Remove excessive "um", "uh", "like", "you know", etc.
5. **Clarity**: Make the text more readable while preserving the original meaning
6. **Structure**: Add appropriate headings if the content has clear sections/topics

**Original Transcript:**
{raw_transcript}

**Instructions:**
- Maintain the original meaning and context
- Use proper markdown formatting
- If there are multiple speakers, use "**Speaker 1:**", "**Speaker 2:**" format
- Add a brief title at the top based on the content
- Keep the improved text natural and conversational

Please provide the improved transcript in markdown format:"""

    try:
        response = client.chat.completions.create(
            model=GPT_MODEL,
            messages=[
                {"role": "system", "content": "You are an expert transcript editor. Improve transcripts while preserving original meaning and context."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=4000,
            temperature=0.3
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"# Fine-tuning Error\n\nCould not process with GPT-4.1: {e}\n\n## Original Transcript\n{raw_transcript}"

def create_azure_client(api_version):
    """å‰µå»º Azure OpenAI å®¢æˆ¶ç«¯"""
    try:
        return AzureOpenAI(
            api_key=API_KEY,
            api_version=api_version,
            azure_endpoint=AZURE_ENDPOINT
        )
    except Exception as e:
        print(f"âŒ ç„¡æ³•å‰µå»º Azure OpenAI å®¢æˆ¶ç«¯: {e}")
        return None

def process_audio_file(audio_file_path):
    """ä¸»è¦è™•ç†å‡½æ•¸"""
    try:
        print("ğŸ” æ¸¬è©¦ OpenAI åº«...")
        if not test_openai_version():
            return {'status': 'error', 'message': 'OpenAI åº«ç‰ˆæœ¬ä¸ç›¸å®¹'}

        print("ğŸ™ï¸ åˆå§‹åŒ– Whisper å®¢æˆ¶ç«¯...")
        whisper_client = create_azure_client(WHISPER_API_VERSION)
        if not whisper_client:
            return {'status': 'error', 'message': 'ç„¡æ³•å‰µå»º Whisper å®¢æˆ¶ç«¯'}

        print("ğŸ“„ æª¢æŸ¥æ–‡ä»¶å¤§å°...")
        file_size_mb = get_file_size_mb(audio_file_path)
        print(f"æ–‡ä»¶å¤§å°: {file_size_mb:.2f}MB")

        # è™•ç†éŸ³é »åˆ†å‰²ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if file_size_mb > 20:
            print("ğŸ”„ æ–‡ä»¶è¼ƒå¤§ï¼Œå˜—è©¦åˆ†å‰²...")
            chunks = split_audio_with_ffmpeg(audio_file_path)
        else:
            chunks = [audio_file_path]

        print(f"ğŸ“ é–‹å§‹è½‰éŒ„ {len(chunks)} å€‹åˆ†æ®µ...")
        full_transcript = []

        for i, chunk_path in enumerate(chunks, 1):
            print(f"ğŸ”„ è½‰éŒ„åˆ†æ®µ {i}/{len(chunks)}")
            text = transcribe_chunk(whisper_client, chunk_path)
            full_transcript.append(text)

        # åˆä½µè½‰éŒ„çµæœ
        raw_transcript = "\n\n".join(full_transcript)
        base_filename = os.path.splitext(os.path.basename(audio_file_path))[0]
        
        # ä¿å­˜åŸå§‹ç‰ˆæœ¬
        no_modified_filename = f"{base_filename}_No-modified.md"
        with open(no_modified_filename, 'w', encoding='utf-8') as f:
            f.write(f"# Raw Transcript - {base_filename}\n\n")
            f.write(f"*Original audio file: {os.path.basename(audio_file_path)}*\n\n")
            f.write("---\n\n")
            f.write(raw_transcript)
        
        print("âœ¨ åˆå§‹åŒ– GPT-4.1 å®¢æˆ¶ç«¯...")
        gpt_client = create_azure_client(GPT_API_VERSION)
        if not gpt_client:
            return {'status': 'error', 'message': 'ç„¡æ³•å‰µå»º GPT-4.1 å®¢æˆ¶ç«¯'}
        
        print("ğŸ”§ ä½¿ç”¨ GPT-4.1 æ”¹å–„å…§å®¹...")
        fine_tuned_transcript = fine_tune_transcript(gpt_client, raw_transcript, base_filename)
        
        # ä¿å­˜æ”¹å–„ç‰ˆæœ¬
        fine_tuned_filename = f"{base_filename}_Fine-tuned.md"
        with open(fine_tuned_filename, 'w', encoding='utf-8') as f:
            f.write(fine_tuned_transcript)

        # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
        if os.path.exists("temp_audio_chunks"):
            for chunk_file in os.listdir("temp_audio_chunks"):
                os.remove(os.path.join("temp_audio_chunks", chunk_file))
            os.rmdir("temp_audio_chunks")

        print("âœ… è™•ç†å®Œæˆï¼")
        return {
            'status': 'success',
            'files': [
                {
                    'name': no_modified_filename,
                    'type': 'No-modified',
                    'content': f"# Raw Transcript - {base_filename}\n\n*Original audio file: {os.path.basename(audio_file_path)}*\n\n---\n\n{raw_transcript}"
                },
                {
                    'name': fine_tuned_filename,
                    'type': 'Fine-tuned',
                    'content': fine_tuned_transcript
                }
            ]
        }

    except Exception as e:
        print(f"âŒ è™•ç†éŒ¯èª¤: {e}")
        return {'status': 'error', 'message': str(e)}

def main():
    print("ğŸ™ï¸ Audio Transcript Fine-Tuner (ç„¡ pydub ç‰ˆæœ¬)")
    print("=" * 40)
    
    if len(sys.argv) > 1:
        # Command line mode
        audio_file_path = sys.argv[1]
        result = process_audio_file(audio_file_path)
        print(json.dumps(result, ensure_ascii=False, indent=2))
    else:
        # Interactive mode
        audio_file_path = input("Please drag and drop your audio file here and press Enter: ").strip().replace('"', '')
        
        if not os.path.exists(audio_file_path):
            print("Error: File not found. Please make sure the path is correct.")
            return
            
        result = process_audio_file(audio_file_path)
        
        if result['status'] == 'success':
            print(f"\n=== Transcription Complete! ===")
            for file_info in result['files']:
                print(f"âœ“ {file_info['name']}")
        else:
            print(f"Error: {result['message']}")

if __name__ == "__main__":
    main()
